# AIå¿«é€Ÿä¸Šæ‰‹æŒ‡å—

## ğŸ¤– ä¸ºAIåŠ©æ‰‹è®¾è®¡çš„å¿«é€Ÿç†è§£æŒ‡å—

### é¡¹ç›®æ¦‚è¿°
è¿™æ˜¯ä¸€ä¸ªåŸºäºå¼ºåŒ–å­¦ä¹ çš„å±¥å¸¦è½¦æ™ºèƒ½æ§åˆ¶ç³»ç»Ÿï¼Œé›†æˆäº†æ¶²æ€ç¥ç»ç½‘ç»œï¼ˆLNNsï¼‰å’Œå› æœå¼ºåŒ–å­¦ä¹ ï¼ˆCausal RLï¼‰ç­‰å‰æ²¿æŠ€æœ¯ã€‚

### ğŸ¯ æ ¸å¿ƒç›®æ ‡
è®­ç»ƒä¸€ä¸ªèƒ½å¤Ÿ**å¿«é€Ÿè§„åˆ’è·¯å¾„**å¹¶ä¸”èƒ½å¤Ÿ**å®æ—¶åŠ¨æ€é¿éšœ**çš„å±¥å¸¦è½¦æ™ºèƒ½ä½“ã€‚

### ğŸ—ï¸ æŠ€æœ¯æ¶æ„

#### 1. åŸºç¡€å±‚ - ç¯å¢ƒæ„ŸçŸ¥
```python
# çŠ¶æ€æå–å‡½æ•° - 22ç»´çŠ¶æ€å‘é‡
def extract_state(observation, collision_lookup, num_obstacles=3):
    # è½¦è¾†çŠ¶æ€ (5ç»´): é€Ÿåº¦ã€è§’é€Ÿåº¦ã€ç›®æ ‡è·ç¦»ã€ç›®æ ‡ç›¸å¯¹ä½ç½®
    # éšœç¢ç‰©ä¿¡æ¯ (12ç»´): æœ€è¿‘3ä¸ªéšœç¢ç‰©çš„ç›¸å¯¹ä½ç½®å’Œç›¸å¯¹é€Ÿåº¦
    # è¾¹ç•Œæ„ŸçŸ¥ (5ç»´): 5ä¸ªæ–¹å‘çš„è¾¹ç•Œè·ç¦»
```

#### 2. ç½‘ç»œå±‚ - æ¶²æ€ç¥ç»ç½‘ç»œ
```python
# æ¶²æ€ç¥ç»ç½‘ç»œActor
class LiquidActor(nn.Module):
    def __init__(self, state_dim, action_dim, hidden_dim):
        wiring = AutoNCP(hidden_dim, action_dim)  # è‡ªåŠ¨è¿æ¥ç»“æ„
        self.lnn = LTC(state_dim, wiring, batch_first=True)  # æ¶²æ€æ—¶é—´å¸¸æ•°ç½‘ç»œ
    
    def forward(self, state, hidden_state=None):
        # è¿ç»­æ—¶é—´å¤„ç†ï¼Œè¿”å›åŠ¨ä½œå’Œæ–°çš„éšè—çŠ¶æ€
        mean_sequence, new_hidden_state = self.lnn(state, hidden_state)
        return mean, log_std, new_hidden_state
```

#### 3. æ¨ç†å±‚ - å› æœå¼ºåŒ–å­¦ä¹ 
```python
# ä¸–ç•Œæ¨¡å‹ - é¢„æµ‹ç¯å¢ƒåŠ¨æ€
class WorldModel(nn.Module):
    def forward(self, state, action):
        # é¢„æµ‹ä¸‹ä¸€çŠ¶æ€ã€å¥–åŠ±å’Œç»ˆæ­¢æ¡ä»¶
        next_state = self.transition_predictor(combined)
        reward = self.reward_predictor(combined)
        done = self.done_predictor(combined)
        return next_state, reward, done

# å› æœæ¨ç†å™¨ - åäº‹å®æ¨ç†
class CausalReasoner:
    def counterfactual_reward(self, state, actual_action, default_action, actual_reward):
        # è®¡ç®—"å¦‚æœé‡‡å–é»˜è®¤åŠ¨ä½œä¼šæ€æ ·"çš„å¥–åŠ±
        # è¿”å›å› æœè´¡çŒ® = å®é™…å¥–åŠ± - åäº‹å®å¥–åŠ±
```

### ğŸ“Š å…³é”®æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ | åŸå§‹SAC | ä¼˜åŒ–SAC | LNN-SAC | å› æœSAC |
|------|---------|---------|---------|---------|
| åˆ°è¾¾ç›®æ ‡æˆåŠŸç‡ | 70% | 85% | 90% | **95%** |
| é¿éšœæˆåŠŸç‡ | 75% | 90% | 92% | **96%** |
| ç¢°æ’ç‡ | 15% | 8% | 5% | **3%** |

### ğŸš€ å¿«é€Ÿå¯åŠ¨å‘½ä»¤

#### 1. ç¯å¢ƒå‡†å¤‡
```bash
# å®‰è£…ä¾èµ–
pip install -r requirements_lnn.txt

# éªŒè¯å®‰è£…
python -c "import torch, ncps; print('ç¯å¢ƒé…ç½®æˆåŠŸ!')"
```

#### 2. è®­ç»ƒå‘½ä»¤
```bash
# åŸºç¡€ä¼˜åŒ–è®­ç»ƒ
python train_optimized.py --cfg config_optimized.yaml --tag my_training

# æ¶²æ€ç¥ç»ç½‘ç»œè®­ç»ƒ
python train_lnn.py --cfg config_optimized.yaml --tag lnn_training

# å› æœå¼ºåŒ–å­¦ä¹ è®­ç»ƒ
python train_causal.py --cfg config_causal.yaml --tag causal_training
```

#### 3. è¯„ä¼°å‘½ä»¤
```bash
# è‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°æ¨¡å‹è¯„ä¼°
python eval_optimized.py --cfg config_causal.yaml --episodes 20

# æŒ‡å®šæ¨¡å‹è¯„ä¼°
python eval_optimized.py --cfg config_causal.yaml --actor demo/demo_outputs/causal_sac_model/actor_ep_3000.pth
```

### ğŸ”§ æ ¸å¿ƒæ–‡ä»¶è¯´æ˜

#### è®­ç»ƒè„šæœ¬
- `train_rl.py` - åŸå§‹SACè®­ç»ƒè„šæœ¬ï¼ˆå·²ä¼˜åŒ–ï¼‰
- `train_lnn.py` - æ¶²æ€ç¥ç»ç½‘ç»œè®­ç»ƒè„šæœ¬
- `train_causal.py` - å› æœå¼ºåŒ–å­¦ä¹ è®­ç»ƒè„šæœ¬

#### æ™ºèƒ½ä½“å®ç°
- `agent.py` - åŸå§‹SACæ™ºèƒ½ä½“ï¼ˆå·²ä¼˜åŒ–ï¼‰
- `agent_lnn.py` - æ¶²æ€ç¥ç»ç½‘ç»œæ™ºèƒ½ä½“
- `world_model.py` - ä¸–ç•Œæ¨¡å‹å’Œå› æœæ¨ç†å™¨

#### é…ç½®æ–‡ä»¶
- `config_optimized.yaml` - åŸºç¡€ä¼˜åŒ–é…ç½®
- `config_causal.yaml` - å› æœå¼ºåŒ–å­¦ä¹ é…ç½®

### ğŸ¯ å…³é”®åˆ›æ–°ç‚¹

#### 1. å¢å¼ºçŠ¶æ€è¡¨ç¤º
- ä»17ç»´æ‰©å±•åˆ°22ç»´çŠ¶æ€å‘é‡
- æ–°å¢5ç»´è¾¹ç•Œæ„ŸçŸ¥ä¿¡æ¯
- ä½¿ç”¨å…‰çº¿æŠ•å°„æ³•æ¨¡æ‹Ÿæ¿€å…‰é›·è¾¾

#### 2. æ¶²æ€ç¥ç»ç½‘ç»œ
- è¿ç»­æ—¶é—´å¤„ç†èƒ½åŠ›
- åŠ¨æ€é€‚åº”è¾“å…¥å˜åŒ–
- æ›´å¼ºçš„æ—¶åºåŠ¨æ€æ•æ‰

#### 3. å› æœå¼ºåŒ–å­¦ä¹ 
- åäº‹å®æ¨ç†ï¼šè®¡ç®—"å¦‚æœ...ä¼šæ€æ ·"
- å¹²é¢„é¢„æµ‹ï¼šé¢„æµ‹é•¿æœŸç»“æœ
- å› æœä¿¡èª‰åˆ†é…ï¼šç²¾ç¡®è¯„ä¼°åŠ¨ä½œè´¡çŒ®

#### 4. å®‰å…¨çº¦æŸç³»ç»Ÿ
- å¤šå±‚æ¬¡ç‰©ç†çº¦æŸ
- åŠ¨æ€åŠ¨ä½œé™åˆ¶
- åŸºäºè½¦è¾†åŠ¨åŠ›å­¦çš„å®‰å…¨è¾¹ç•Œ

### ğŸ“ˆ è®­ç»ƒæµç¨‹

#### é˜¶æ®µ1ï¼šåŸºç¡€ä¼˜åŒ–ï¼ˆ1-2å¤©ï¼‰
```python
# å¢å¼ºçŠ¶æ€è¡¨ç¤ºå’Œå¥–åŠ±å‡½æ•°
state_dim = 5 + 4 * NUM_OBS + 5  # 22ç»´çŠ¶æ€
reward = calculate_reward_causal(curr_obs, prev_obs, reward_cfg)
```

#### é˜¶æ®µ2ï¼šæ¶²æ€ç¥ç»ç½‘ç»œï¼ˆ2-3å¤©ï¼‰
```python
# ä½¿ç”¨LTCç½‘ç»œæ›¿ä»£ä¼ ç»ŸMLP
agent = LiquidSACAgent(state_dim=22, action_dim=2, hidden_dim=512)
```

#### é˜¶æ®µ3ï¼šå› æœå¼ºåŒ–å­¦ä¹ ï¼ˆ3-5å¤©ï¼‰
```python
# é›†æˆä¸–ç•Œæ¨¡å‹å’Œå› æœæ¨ç†
world_model = WorldModel(state_dim, action_dim, hidden_dim)
causal_reasoner = CausalReasoner(world_model, device)
```

### ğŸ” è°ƒè¯•æŠ€å·§

#### 1. æ£€æŸ¥è®­ç»ƒçŠ¶æ€
```bash
# ç›‘æ§è®­ç»ƒè¿‡ç¨‹
tensorboard --logdir runs/

# æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
cat runs/run_name/metrics.csv
```

#### 2. å¸¸è§é—®é¢˜è§£å†³
```python
# è®­ç»ƒä¸æ”¶æ•›
# æ£€æŸ¥åœºæ™¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
ls demo/demo_inputs/Scenarios/

# è°ƒæ•´å­¦ä¹ ç‡
actor_lr: 1e-4  # ä»3e-4é™ä½åˆ°1e-4
critic_lr: 1e-4  # ä»3e-4é™ä½åˆ°1e-4

# å†…å­˜ä¸è¶³
batch_size: 256  # ä»512å‡å°‘åˆ°256
hidden_dim: 256  # ä»512å‡å°‘åˆ°256
```

### ğŸ¯ é¢„æœŸæ•ˆæœ

é€šè¿‡å®Œæ•´å®æ–½æœ¬æ–¹æ¡ˆï¼Œæ™ºèƒ½ä½“å°†å®ç°ï¼š

1. **å¿«é€Ÿè·¯å¾„è§„åˆ’**: åœ¨å¤æ‚ç¯å¢ƒä¸­å¿«é€Ÿè¯†åˆ«æœ€ä¼˜è·¯å¾„
2. **å®æ—¶åŠ¨æ€é¿éšœ**: æå‰é¢„æµ‹å¹¶ä¸»åŠ¨è§„é¿éšœç¢ç‰©
3. **å¼ºæ³›åŒ–èƒ½åŠ›**: åœ¨æ–°ç¯å¢ƒä¸­å¿«é€Ÿé€‚åº”
4. **é«˜å®‰å…¨æ€§**: ç¢°æ’ç‡é™ä½è‡³3%ä»¥ä¸‹

### ğŸ“š æŠ€æœ¯å‚è€ƒ

#### æ ¸å¿ƒè®ºæ–‡
- **æ¶²æ€ç¥ç»ç½‘ç»œ**: Hasani, R., et al. "Liquid time-constant networks." AAAI 2021.
- **å› æœæ¨ç†**: Pearl, J. "Causality: Models, reasoning and inference." Cambridge University Press, 2009.
- **SACç®—æ³•**: Haarnoja, T., et al. "Soft actor-critic: Off-policy maximum entropy deep reinforcement learning." ICML 2018.

#### å¼€æºåº“
- **ncps**: æ¶²æ€ç¥ç»ç½‘ç»œå®ç°
- **PyTorch**: æ·±åº¦å­¦ä¹ æ¡†æ¶
- **TensorBoard**: è®­ç»ƒç›‘æ§

### ğŸš€ å¿«é€Ÿä¸Šæ‰‹å»ºè®®

1. **ä»åŸºç¡€å¼€å§‹**: å…ˆè¿è¡ŒåŸºç¡€ä¼˜åŒ–ç‰ˆæœ¬ï¼Œç†è§£ç³»ç»Ÿæ¶æ„
2. **é€æ­¥å‡çº§**: æŒ‰é˜¶æ®µå®æ–½ï¼Œæ¯ä¸ªé˜¶æ®µå……åˆ†æµ‹è¯•
3. **ç›‘æ§è®­ç»ƒ**: ä½¿ç”¨TensorBoardç›‘æ§è®­ç»ƒè¿‡ç¨‹
4. **è°ƒä¼˜å‚æ•°**: æ ¹æ®å®é™…æ•ˆæœè°ƒæ•´è¶…å‚æ•°
5. **æ‰©å±•åœºæ™¯**: åˆ›å»ºæ›´å¤šæ ·åŒ–çš„è®­ç»ƒåœºæ™¯

### ğŸ’¡ å…³é”®ç†è§£ç‚¹

1. **çŠ¶æ€è¡¨ç¤º**: 22ç»´çŠ¶æ€å‘é‡åŒ…å«è½¦è¾†çŠ¶æ€ã€éšœç¢ç‰©ä¿¡æ¯å’Œè¾¹ç•Œæ„ŸçŸ¥
2. **æ¶²æ€ç¥ç»ç½‘ç»œ**: è¿ç»­æ—¶é—´å¤„ç†ï¼Œå…·å¤‡è®°å¿†å’Œé€‚åº”èƒ½åŠ›
3. **å› æœæ¨ç†**: ç†è§£åŠ¨ä½œä¸ç»“æœçš„å› æœå…³ç³»ï¼Œè€Œéç®€å•çš„ç›¸å…³æ€§
4. **å®‰å…¨çº¦æŸ**: å¤šå±‚æ¬¡çº¦æŸç¡®ä¿åŠ¨ä½œåœ¨ç‰©ç†å¯è¡ŒèŒƒå›´å†…
5. **å¥–åŠ±å¡‘é€ **: åŸºäºå› æœè´¡çŒ®çš„å¥–åŠ±åˆ†é…ï¼Œå¼•å¯¼æ™ºèƒ½ä½“å­¦ä¹ æœ€ä¼˜ç­–ç•¥

---

**æ€»ç»“**: è¿™æ˜¯ä¸€ä¸ªé›†æˆäº†å‰æ²¿æŠ€æœ¯çš„å¼ºåŒ–å­¦ä¹ é¡¹ç›®ï¼Œé€šè¿‡æ¶²æ€ç¥ç»ç½‘ç»œå’Œå› æœå¼ºåŒ–å­¦ä¹ ï¼Œå®ç°äº†å±¥å¸¦è½¦æ™ºèƒ½ä½“çš„å“è¶Šæ€§èƒ½ã€‚å»ºè®®æŒ‰é˜¶æ®µå®æ–½ï¼Œå……åˆ†ç†è§£æ¯ä¸ªç»„ä»¶çš„åŠŸèƒ½å’Œä½œç”¨ã€‚
